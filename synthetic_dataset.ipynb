{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1c047da-b368-4add-b821-8cf52a39a556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "colors = {\n",
    "  'r': np.array([255,   0,   0], dtype=np.uint8),\n",
    "  'o': np.array([255, 128,   0], dtype=np.uint8),\n",
    "  'y': np.array([255, 255,   0], dtype=np.uint8),\n",
    "  'g': np.array([0,   255,   0], dtype=np.uint8),\n",
    "  'b': np.array([0,   128, 255], dtype=np.uint8),\n",
    "  'i': np.array([0,     0, 255], dtype=np.uint8),\n",
    "  'v': np.array([128,   0, 255], dtype=np.uint8)\n",
    "}\n",
    "\n",
    "imglen = 4\n",
    "imgshape = (imglen, imglen, 3)\n",
    "topleft_corner = (0,0)\n",
    "topright_corner = (0,imglen-1)\n",
    "botleft_corner = (imglen-1,0)\n",
    "botright_corner = (imglen-1,imglen-1)\n",
    "\n",
    "midpoint = (imglen//2, imglen//2)\n",
    "\n",
    "# column divisions to get quadrants and columns \n",
    "topleft_col1 = [(0,0),(1,0)]\n",
    "topleft_col2 = [(0,1),(1,1)]\n",
    "topright_col1 = [(0,2),(1,2)]\n",
    "topright_col2 = [(0,3),(1,3)]\n",
    "botleft_col1 = [(2,0),(3,0)]\n",
    "botleft_col2 = [(2,1),(3,1)]\n",
    "botright_col1 = [(2,2),(3,2)]\n",
    "botright_col2 = [(2,3),(3,3)]\n",
    "\n",
    "# # more interactive way to get column divisions to get quadrants and columns \n",
    "# column_divisions = [ [] for _ in range(imglen * 2) ]\n",
    "# for r in range(imglen):\n",
    "#     for c in range(imglen):\n",
    "#         if r < imglen//2:\n",
    "#             column_divisions[c].append((r,c))\n",
    "#         else:\n",
    "#             column_divisions[c+imglen].append((r,c))\n",
    "\n",
    "def random_color(exclude = []):\n",
    "    # color choices for the grid \n",
    "    color_choices = ['r','g','b','v']\n",
    "    if len(exclude) > 0:\n",
    "        for color in colors:\n",
    "            if np.array_equal(colors[color], exclude):\n",
    "                color_choices.remove(color)\n",
    "    return colors[np.random.choice(color_choices)]\n",
    "\n",
    "def Bern(p):\n",
    "    return np.random.rand() < p\n",
    "\n",
    "def change_image(image, skip_pixels, skip_color):\n",
    "    for row_idx in range(image.shape[0]):\n",
    "        for col_idx in range(image.shape[1]):\n",
    "            index = (row_idx, col_idx)\n",
    "            if index not in skip_pixels:\n",
    "                # if there are pixels with color outside the designated pixels \n",
    "                if (np.array_equal(image[index], skip_color)):\n",
    "                    image[index] = random_color(exclude = skip_color)\n",
    "\n",
    "def ensure_class_0_rules_apply(img):\n",
    "    skip_pixels = []\n",
    "    if Bern(0.5):\n",
    "        color = img[topleft_corner]\n",
    "        img[topright_corner] = color\n",
    "        skip_pixels.extend([topleft_corner, topright_corner])\n",
    "        if Bern(0.5):\n",
    "            img[botleft_corner] = color\n",
    "            skip_pixels.append(botleft_corner)\n",
    "        else:\n",
    "            img[botright_corner] = color\n",
    "            skip_pixels.append(botright_corner)\n",
    "    else:\n",
    "        color = img[botleft_corner]\n",
    "        img[botright_corner] = color\n",
    "        skip_pixels.extend([botleft_corner, botright_corner])\n",
    "        if Bern(0.5):\n",
    "            img[topright_corner] = color\n",
    "            skip_pixels.append(topright_corner)\n",
    "        else:\n",
    "            img[topleft_corner] = color\n",
    "            skip_pixels.append(topleft_corner)\n",
    "    \n",
    "    # make sure the other pixels don't have the color in the 3 corners\n",
    "    change_image(img, skip_pixels, color)\n",
    "    \n",
    "    # if image has 3 same corners & middle 2 same columns (label 0 and 2)\n",
    "    if check_class_2(img) > 0:\n",
    "        color_choices = ['r','g','b','v']\n",
    "        midcolor = img[midpoint]\n",
    "        for color_name in colors:\n",
    "            if np.array_equal(colors[color_name], color):\n",
    "                color_choices.remove(color_name)\n",
    "            elif np.array_equal(colors[color_name], midcolor):\n",
    "                color_choices.remove(color_name)\n",
    "        random.shuffle(color_choices)\n",
    "        img[midpoint] = colors[color_choices[0]]\n",
    "    return img\n",
    "                                \n",
    "def ensure_class_1_rules_apply(img, percentages):\n",
    "    p = np.random.rand()\n",
    "    if p < percentages[0]:\n",
    "        color = img[botleft_corner]\n",
    "        skip_pixels = botleft_col1 + botleft_col2 + topright_col1 + topright_col2\n",
    "    elif p < percentages[1]:\n",
    "        color = img[topleft_corner]\n",
    "        skip_pixels = topleft_col1 + topleft_col2 + topright_col1 + topright_col2\n",
    "    elif p < percentages[2]:\n",
    "        color = img[topright_corner]\n",
    "        skip_pixels = topright_col1 + topright_col2 + botright_col1 + botright_col2\n",
    "    elif p < percentages[3]:\n",
    "        color = img[topleft_corner]\n",
    "        skip_pixels = topleft_col1 + topleft_col2 + botright_col1 + botright_col2\n",
    "    elif p < percentages[4]:\n",
    "        color = img[topleft_corner]\n",
    "        skip_pixels = topleft_col1 + topleft_col2 + botleft_col1 + botleft_col2\n",
    "    else: \n",
    "        color = img[botleft_corner]\n",
    "        skip_pixels = botleft_col1 + botleft_col2 + botright_col1 + botright_col2\n",
    "        \n",
    "    for pixel in skip_pixels:\n",
    "        img[pixel] = color\n",
    "    change_image(img, skip_pixels, color)\n",
    "    return img \n",
    "    \n",
    "def ensure_class_2_rules_apply(img, percentages):\n",
    "    p = np.random.rand()\n",
    "    class_0_confused = False\n",
    "    if p < percentages[0]:\n",
    "        color = img[topleft_corner]\n",
    "        skip_pixels = topleft_col1 + topright_col2 + botleft_col1 + botright_col2\n",
    "    elif p < percentages[1]:\n",
    "        color = img[topleft_corner]\n",
    "        skip_pixels = topleft_col1 + topright_col1 + botleft_col1 + botright_col1\n",
    "    elif p < percentages[2]:\n",
    "        color = img[topleft_corner]\n",
    "        skip_pixels = topleft_col1 + topleft_col2 + botleft_col1 + botleft_col2\n",
    "    elif p < percentages[3]:\n",
    "        color = img[(0,1)]\n",
    "        skip_pixels = topleft_col2 + topright_col1 + botleft_col2 + botright_col1\n",
    "        # additional check that 3 corners are not same color\n",
    "        class_0_confused = True\n",
    "    elif p < percentages[4]:\n",
    "        color = img[topright_corner]\n",
    "        skip_pixels = topright_col1 + topright_col2 + botright_col1 + botright_col2\n",
    "    else: \n",
    "        color = img[topright_corner]\n",
    "        skip_pixels = topleft_col2 + topright_col2 + botleft_col2 + botright_col2\n",
    "        \n",
    "    for pixel in skip_pixels:\n",
    "        img[pixel] = color\n",
    "    change_image(img, skip_pixels, color)\n",
    "    \n",
    "    # for image with middle two columns, the 3 corners can have same color \n",
    "    if class_0_confused:\n",
    "        color_choices = ['r','g','b','v']\n",
    "        for color_name in colors:\n",
    "            if np.array_equal(colors[color_name], color):\n",
    "                color_choices.remove(color_name)\n",
    "        random.shuffle(color_choices)\n",
    "        img[topleft_corner] = colors[color_choices[0]]\n",
    "        img[botleft_corner] = colors[color_choices[1]]\n",
    "        img[botright_corner] = colors[color_choices[2]]\n",
    "        img[topright_corner] = colors[color_choices[np.random.randint(0, 3)]]\n",
    "    return img\n",
    "\n",
    "# center square is same color \n",
    "def center_square_same_color(img):\n",
    "    # Define the actions as a list of functions or lambda expressions\n",
    "    midpoint = imglen//2\n",
    "    center_color = img[(midpoint, midpoint)]\n",
    "    skip_pixels = [(midpoint, midpoint), (midpoint-1, midpoint-1), (midpoint-1, midpoint), (midpoint, midpoint-1)]\n",
    "    for pixel in skip_pixels:\n",
    "        img[pixel] = center_color\n",
    "        \n",
    "    img = change_image(img, skip_pixels, center_color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_image(label, percentages):\n",
    "    image = np.array([[random_color()\n",
    "                      for _ in range(imglen)]\n",
    "                        for __ in range(imglen)], dtype=np.uint8)\n",
    "\n",
    "    if label == 0:\n",
    "        return ensure_class_0_rules_apply(image)\n",
    "        # return center_square_same_color(image)\n",
    "    elif label == 1:\n",
    "        return ensure_class_1_rules_apply(image, percentages)\n",
    "    else:\n",
    "        return ensure_class_2_rules_apply(image, percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45cb6eed-a0c0-4fc3-8383-631677c72b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_circle(img):\n",
    "    midpoint = imglen//2\n",
    "    center_color = img[(midpoint, midpoint)]\n",
    "    skip_pixels = [(midpoint, midpoint), (midpoint-1, midpoint-1), (midpoint-1, midpoint), (midpoint, midpoint-1)]\n",
    "    for r in range(len(img)):\n",
    "        for c in range(len(img[r])):\n",
    "            index = (r,c)\n",
    "            if index in skip_pixels:\n",
    "                if np.array_equal(img[index], center_color):\n",
    "                    return 1 \n",
    "                else:\n",
    "                    return -1 \n",
    "            else:\n",
    "                if np.array_equal(img[index], center_color):\n",
    "                    return -1\n",
    "                else:\n",
    "                    return 1\n",
    "                \n",
    "def check_class_0(img):\n",
    "    label = -1\n",
    "    color = img[topleft_corner]\n",
    "    if (np.array_equal(img[botleft_corner],color)) and (np.array_equal(img[topright_corner], color)):\n",
    "        label = 0\n",
    "    elif (np.array_equal(img[botright_corner],color)) and (np.array_equal(img[topright_corner], color)):\n",
    "        label = 1\n",
    "    elif (np.array_equal(img[botleft_corner], color)) and (np.array_equal(img[botright_corner], color)):\n",
    "        label = 3\n",
    "    \n",
    "    color = img[topright_corner]\n",
    "    if (np.array_equal(img[botleft_corner], color)) and (np.array_equal(img[botright_corner], color)):\n",
    "        if (np.array_equal(img[topleft_corner], color)):\n",
    "            label = 10\n",
    "        else:\n",
    "            label = 2\n",
    "    return label \n",
    "\n",
    "def check_individual_class(image, color, label_pixels):\n",
    "    for pixel in label_pixels:\n",
    "        if not np.array_equal(image[pixel], color):\n",
    "            return False \n",
    "    return True\n",
    "\n",
    "def check_class_1(img):\n",
    "    label0_pixels = botleft_col1 + botleft_col2 + topright_col1 + topright_col2\n",
    "    label1_pixels = topleft_col1 + topleft_col2 + topright_col1 + topright_col2\n",
    "    label2_pixels = topright_col1 + topright_col2 + botright_col1 + botright_col2\n",
    "    label3_pixels = topleft_col1 + topleft_col2 + botright_col1 + botright_col2\n",
    "    label4_pixels = topleft_col1 + topleft_col2 + botleft_col1 + botleft_col2\n",
    "    label5_pixels = botleft_col1 + botleft_col2 + botright_col1 + botright_col2\n",
    "    \n",
    "    if check_individual_class(img, img[botleft_corner], label0_pixels):\n",
    "        return 0\n",
    "    elif check_individual_class(img, img[topleft_corner], label1_pixels):\n",
    "        return 1\n",
    "    elif check_individual_class(img, img[topright_corner], label2_pixels):\n",
    "        return 2\n",
    "    elif check_individual_class(img, img[topleft_corner], label3_pixels):\n",
    "        return 3\n",
    "    elif check_individual_class(img, img[topleft_corner], label4_pixels):\n",
    "        return 4\n",
    "    elif check_individual_class(img, img[botleft_corner], label5_pixels):\n",
    "        return 5\n",
    "    else:\n",
    "        return -1 \n",
    "    \n",
    "def check_class_2(img):\n",
    "    label0_pixels = topleft_col1 + topright_col2 + botleft_col1 + botright_col2\n",
    "    label1_pixels = topleft_col1 + topright_col1 + botleft_col1 + botright_col1\n",
    "    label2_pixels = topleft_col1 + topleft_col2 + botleft_col1 + botleft_col2\n",
    "    label3_pixels = topleft_col2 + topright_col1 + botleft_col2 + botright_col1\n",
    "    label4_pixels = topright_col1 + topright_col2 + botright_col1 + botright_col2\n",
    "    label5_pixels = topleft_col2 + topright_col2 + botleft_col2 + botright_col2\n",
    "    \n",
    "    if check_individual_class(img, img[topleft_corner], label0_pixels):\n",
    "        return 0\n",
    "    elif check_individual_class(img, img[topleft_corner], label1_pixels):\n",
    "        return 1\n",
    "    elif check_individual_class(img, img[topleft_corner], label2_pixels):\n",
    "        return 2\n",
    "    elif check_individual_class(img, img[(0,1)], label3_pixels):\n",
    "        return 3\n",
    "    elif check_individual_class(img, img[topright_corner], label4_pixels):\n",
    "        return 4\n",
    "    elif check_individual_class(img, img[topright_corner], label5_pixels):\n",
    "        return 5\n",
    "    else:\n",
    "        return -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "32602884-66d5-463c-9dcd-27a8807f1a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_y = ([0] * 1500) + ([1] * 1500) + ([2] * 1500)\n",
    "test_y = ([0] * 500) + ([1] * 500) + ([2] * 500)\n",
    "random.shuffle(train_y)\n",
    "random.shuffle(test_y)\n",
    "\n",
    "train_y = np.array(train_y).astype(np.uint8)\n",
    "test_y = np.array(test_y).astype(np.uint8)\n",
    "\n",
    "test_percentages = {0: 0.17, 1: 0.34, 2:0.51, 3:0.68, 4:0.85}  \n",
    "train_percentages = {0: 0.17, 1: 0.34, 2:0.51, 3:0.68, 4:0.85}\n",
    "# train_percentages = {0: 0.21, 1: 0.42, 2: 0.5, 3:0.71, 4:0.79}  \n",
    "# train_percentages = {0: 0.225, 1: 0.45, 2: 0.5, 3:0.725, 4:0.775}\n",
    "# train_percentages = {0: 0.25, 1: 0.5, 2: 0, 3:0.75, 4:0}  \n",
    "\n",
    "data = (\n",
    "  np.array([generate_image(y, train_percentages) for y in train_y]),\n",
    "  np.array([generate_image(y, test_percentages) for y in test_y]), train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c170b10a-d11c-4056-88f1-e29c1f446b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "978\n"
     ]
    }
   ],
   "source": [
    "train_x = data[0]\n",
    "train_y = data[2]\n",
    "\n",
    "class_0 = []\n",
    "class_1 = 0\n",
    "for i in range(train_x.shape[0]):\n",
    "    # if center are the same color\n",
    "    # if train_y[i] == 0 and check_circle(train_x[i]) < 0:\n",
    "    #     class_0.append(i)\n",
    "        \n",
    "    # if 3 corners are the same color\n",
    "    if check_class_0(train_x[i]) > 0:\n",
    "        if check_class_1(train_x[i]) > 0 or check_class_2(train_x[i]) > 0:\n",
    "            class_0.append(i)\n",
    "            print (train_y[i])\n",
    "    \n",
    "    # if two quadrants are the same color \n",
    "    if check_class_1(train_x[i]) > 0:\n",
    "        if check_class_2(train_x[i]) > 0:\n",
    "            class_1 += 1\n",
    "print (class_0)\n",
    "print (class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "adb98d57-8ab2-47c8-a865-2b42a9fb57e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1500\n",
      "1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {0: 339, 1: 399, 2: 386, 3: 376},\n",
       " 1: {0: 253, 1: 255, 2: 246, 3: 266, 4: 253, 5: 227},\n",
       " 2: {0: 256, 1: 257, 2: 228, 3: 293, 4: 251, 5: 215}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = data[0]\n",
    "train_y = data[2]\n",
    "\n",
    "count = {0: {0:0, 1:0, 2:0, 3:0}, 1: {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}, 2:{0:0, 1:0, 2:0, 3:0, 4:0, 5:0}}\n",
    "\n",
    "class_0 = 0\n",
    "class_1 = 0\n",
    "class_2 = 0\n",
    "for i in range(train_x.shape[0]):\n",
    "    if train_y[i] == 0:\n",
    "        count[0][check_class_0(train_x[i])] += 1\n",
    "        class_0 += 1\n",
    "    if train_y[i] == 1:\n",
    "        count[1][check_class_1(train_x[i])] += 1\n",
    "        class_1 += 1\n",
    "    if train_y[i] == 2:\n",
    "        count[2][check_class_2(train_x[i])] += 1\n",
    "        class_2 += 1\n",
    "        \n",
    "print (class_0)\n",
    "print (class_1)\n",
    "print (class_2)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11d2b56b-0a03-4bb2-8421-9d645192b7cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {0: 128, 1: 115, 2: 116, 3: 141},\n",
       " 1: {0: 75, 1: 94, 2: 81, 3: 93, 4: 77, 5: 80},\n",
       " 2: {0: 100, 1: 78, 2: 95, 3: 87, 4: 63, 5: 77}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = data[1]\n",
    "test_y = data[3]\n",
    "\n",
    "count = {0: {0:0, 1:0, 2:0, 3:0}, 1: {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}, 2:{0:0, 1:0, 2:0, 3:0, 4:0, 5:0}}\n",
    "class_0 = 0\n",
    "class_1 = 0\n",
    "class_2 = 0\n",
    "for i in range(test_x.shape[0]):\n",
    "    if test_y[i] == 0:\n",
    "        count[0][check_class_0(test_x[i])] += 1\n",
    "        class_0 += 1\n",
    "    if test_y[i] == 1:\n",
    "        count[1][check_class_1(test_x[i])] += 1\n",
    "        class_1 += 1\n",
    "    if test_y[i] == 2:\n",
    "        count[2][check_class_2(test_x[i])] += 1\n",
    "        class_2 += 1\n",
    "        \n",
    "print (class_0)\n",
    "print (class_1)\n",
    "print (class_2)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16cf7a92-deb5-4906-a560-eba86df492e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "316\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "test_x = data[1]\n",
    "test_y = data[3]\n",
    "\n",
    "class_0 = 0\n",
    "class_1 = 0\n",
    "class_2 = 0\n",
    "for i in range(test_x.shape[0]):\n",
    "    # if 3 corners are the same color\n",
    "    if check_class_0(test_x[i]) > 0:\n",
    "        if check_class_1(test_x[i]) > 0 or check_class_2(test_x[i]) > 0:\n",
    "            class_0 += 1\n",
    "            \n",
    "    if check_class_1(test_x[i]) > 0:\n",
    "        if check_class_2(test_x[i]) > 0:\n",
    "            class_1 += 1\n",
    "            if check_class_0(test_x[i]) > 0:\n",
    "                class_2 += 1\n",
    "print (class_0)\n",
    "print (class_1)\n",
    "print (class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "734df1cb-57b2-4c8a-aa89-635e70369f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PixelDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        x = self.X[ind].ravel() / 255.0\n",
    "        y = self.y[ind]\n",
    "        return x, y\n",
    "\n",
    "train_set = PixelDataset(train_x, train_y)\n",
    "test_set  = PixelDataset(test_x, test_y)\n",
    "\n",
    "batch_size = 24\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40bb50f5-3889-4044-a46b-c82cc320409b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(images)\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    print ('Accuracy: ' + str(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52b4561b-8a82-4811-a123-75701a448fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss   1.08 | Accuracy 0.43\n",
      "Accuracy: 0.5853333333333334\n",
      "Epoch 10 | Loss   0.33 | Accuracy 0.86\n",
      "Accuracy: 0.8473333333333334\n",
      "Epoch 20 | Loss   0.28 | Accuracy 0.87\n",
      "Accuracy: 0.854\n",
      "Epoch 30 | Loss   0.26 | Accuracy 0.88\n",
      "Accuracy: 0.8626666666666667\n",
      "Epoch 40 | Loss   0.25 | Accuracy 0.89\n",
      "Accuracy: 0.8593333333333333\n",
      "Epoch 50 | Loss   0.24 | Accuracy 0.89\n",
      "Accuracy: 0.8653333333333333\n",
      "Epoch 60 | Loss   0.23 | Accuracy 0.89\n",
      "Accuracy: 0.858\n",
      "Epoch 70 | Loss   0.22 | Accuracy 0.90\n",
      "Accuracy: 0.856\n",
      "Epoch 80 | Loss   0.22 | Accuracy 0.90\n",
      "Accuracy: 0.856\n",
      "Epoch 90 | Loss   0.21 | Accuracy 0.90\n",
      "Accuracy: 0.8526666666666667\n",
      "Epoch 100 | Loss   0.20 | Accuracy 0.90\n",
      "Accuracy: 0.854\n",
      "Epoch 110 | Loss   0.20 | Accuracy 0.91\n",
      "Accuracy: 0.854\n",
      "Epoch 120 | Loss   0.20 | Accuracy 0.91\n",
      "Accuracy: 0.8526666666666667\n",
      "Epoch 130 | Loss   0.19 | Accuracy 0.91\n",
      "Accuracy: 0.8493333333333334\n",
      "Epoch 140 | Loss   0.19 | Accuracy 0.91\n",
      "Accuracy: 0.858\n",
      "Epoch 150 | Loss   0.19 | Accuracy 0.91\n",
      "Accuracy: 0.8533333333333334\n",
      "Epoch 160 | Loss   0.18 | Accuracy 0.92\n",
      "Accuracy: 0.85\n",
      "Epoch 170 | Loss   0.18 | Accuracy 0.92\n",
      "Accuracy: 0.8526666666666667\n",
      "Epoch 180 | Loss   0.18 | Accuracy 0.92\n",
      "Accuracy: 0.8553333333333333\n",
      "Epoch 190 | Loss   0.17 | Accuracy 0.92\n",
      "Accuracy: 0.8506666666666667\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4 * 4 * 3, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 3)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        correct += (labels == pred).sum().item()\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch %d | Loss %6.2f | Accuracy %.2f' % (epoch, sum(losses)/len(losses), correct / len(train_loader.dataset)))\n",
    "        test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc56d8e3-3a67-48e8-bc0d-964e2fe9cee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute model outputs on test instances\n",
    "labels = []\n",
    "outputs = []\n",
    "\n",
    "for i, (image, label) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        images = image.to(device).float()\n",
    "    labels.extend(label.numpy())\n",
    "\n",
    "    # Compute model inferences\n",
    "    output = model(images)\n",
    "    output = torch.nn.functional.softmax(output, dim=1).squeeze(0).detach().cpu().numpy()\n",
    "    outputs.append(output)\n",
    "    \n",
    "outputs = np.vstack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8737b804-b574-43bd-b4e8-9e35af6d39e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {1: 20, 2: 19}, 1: {0: 9, 2: 77}, 2: {0: 15, 1: 93}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = {0: {1: 0, 2: 0}, 1: {0: 0, 2: 0}, 2: {0: 0, 1: 0}}\n",
    "\n",
    "predictions = [np.argmax(output) for output in outputs]\n",
    "for i in range(len(predictions)):\n",
    "    label = labels[i]\n",
    "    prediction = predictions[i]\n",
    "    if (label != prediction):\n",
    "        incorrect[label][prediction] += 1\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0d7df34-baab-4813-aabf-641a5c568341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL STATS:\n",
      "Accuracy: 84.47%\n",
      "Mean prediction confidence: 0.91\n",
      "Mean prediction confidence (correct): 0.95\n",
      "Mean prediction confidence (incorrect): 0.95\n"
     ]
    }
   ],
   "source": [
    "# Print model performance statistics\n",
    "predictions = [np.argmax(output) for output in outputs]\n",
    "correctness = [label == predictions[i] for i, label in enumerate(labels)]\n",
    "correct_inds = [i for i, label in enumerate(labels) if label == predictions[i]]\n",
    "incorrect_inds = [i for i, label in enumerate(labels) if label != predictions[i]]\n",
    "print(f'MODEL STATS:')\n",
    "print(f'Accuracy: {len(correct_inds) / len(labels):.2%}')\n",
    "print(f'Mean prediction confidence: {np.mean([np.max(output) for output in outputs]):.2f}')\n",
    "print(f'Mean prediction confidence (correct): {np.mean([np.max(outputs[i]) for i in correct_inds]):.2f}')\n",
    "print(f'Mean prediction confidence (incorrect): {np.mean([np.max(outputs[i]) for i in correct_inds]):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "466be93a-b46f-4c1c-b5ec-d68e5228a161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with 6 nodes across 3 levels.\n"
     ]
    }
   ],
   "source": [
    "from treelib import Tree\n",
    "def make_tree(misaligned = False):\n",
    "    tree = Tree()\n",
    "\n",
    "    # Add root\n",
    "    tree.create_node(tag='root', identifier='root', parent=None, data=None)\n",
    "\n",
    "    # Add superclass nodes\n",
    "    tree.create_node(tag='f1', identifier='f1', parent='root', data=None)\n",
    "    tree.create_node(tag='f2', identifier='f2', parent='root', data=None)\n",
    "\n",
    "    # Add class nodes\n",
    "    tree.create_node(tag='f1a', \n",
    "                     identifier='f1a', \n",
    "                     parent='f1', \n",
    "                     data=None)\n",
    "    if misaligned:\n",
    "        tree.create_node(tag='f2a', \n",
    "                         identifier='f2a', \n",
    "                         parent='f1', \n",
    "                         data=None)\n",
    "    else: \n",
    "        tree.create_node(tag='f2a', \n",
    "                         identifier='f2a', \n",
    "                         parent='f2', \n",
    "                         data=None)\n",
    "    tree.create_node(tag='f2b', \n",
    "                     identifier='f2b', \n",
    "                     parent='f2', \n",
    "                     data=None)\n",
    "    return tree\n",
    "tree = make_tree()\n",
    "print(f'Tree with {tree.size()} nodes across {tree.depth() + 1} levels.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3d7c2455-a3f0-448a-9030-98af2ee29681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root (1.00)\n",
      "├── f1 (1.00)\n",
      "│   ├── f1a (1.00)\n",
      "│   └── f2a (0.00)\n",
      "└── f2 (0.00)\n",
      "    └── f2b (0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show(tree, hide_zeros=False):\n",
    "    string = tree.show(stdout=False)\n",
    "    for node_id, node in tree.nodes.items():\n",
    "        node_value = node.data\n",
    "        if node_value is not None:\n",
    "            node_value = round(node_value, 2)\n",
    "            if node_value == 0 and hide_zeros:\n",
    "                node_value = ''\n",
    "            else:\n",
    "                node_value = f'{node_value:.2f}'\n",
    "        string = string.replace(f'{node_id}\\n', f'{node_id} ({node_value})\\n')\n",
    "    return string\n",
    "print (show(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b377853a-681b-46ba-8246-72e39f07b8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def propagate(outputs, tree):\n",
    "    \"\"\"Propagate model outputs through the tree.\"\"\"\n",
    "    # Assign values to the leaves of the tree\n",
    "    for i, value in enumerate(outputs):\n",
    "        if i == 0:\n",
    "            name = 'f1a'\n",
    "        elif i == 1:\n",
    "            name = 'f2a'\n",
    "        elif i == 2:\n",
    "            name = 'f2b'\n",
    "        else:\n",
    "            name = ''\n",
    "        node = tree.get_node(name)\n",
    "        node.data = value\n",
    "        \n",
    "    # Propagate values up the tree\n",
    "    level = tree.depth() - 1 # leaf level = depth\n",
    "    while level >= 0:\n",
    "        nodes = tree.filter_nodes(lambda x: tree.depth(x) == level)\n",
    "        for node in nodes:\n",
    "            reachable_leaves = tree.leaves(node.identifier)\n",
    "            node.data = np.sum([leaf.data for leaf in reachable_leaves])\n",
    "        level -= 1\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f58834c-c284-41ee-a0a2-61513d3a0b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Measure abstraction alignment by propagating model outputs through the hierarchy\n",
    "aligned_trees = []\n",
    "for i in range(len(labels)):\n",
    "    # print (outputs[i])\n",
    "    tree = propagate(outputs[i], make_tree())\n",
    "    aligned_trees.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5683fcfa-b49d-47d8-8b10-77843ea6fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIDENCE, CORRECTNESS, AND ENTROPY FOR EVERY INSTANCE AT THE CLASS AND SUPERCLASS LEVEL\n",
      "Class confidence (1500, 3); all sum to one: True\n",
      "Class correctness (1500,); equal to accuracy: 84.47%\n",
      "Class entropy (1500,)\n",
      "Superclass confidence (1500, 2); all sum to one: True\n",
      "Superclass correctness (1500,); superclass accuracy: 95.93%\n",
      "Superclass entropy (1500,)\n",
      "ACCURACY -- class-level: 84.47%; superclass-level: 95.93%\n",
      "ENTROPY --- class-level: 0.20; superclass-level: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Compute class and superclass accuracy and entropy\n",
    "from scipy import stats\n",
    "# Confidence vectors, correctness, and entropy for the class and superclass levels for every instance\n",
    "class_confidences = []\n",
    "class_correctness = []\n",
    "class_entropy = []\n",
    "superclass_confidences = []\n",
    "superclass_correctness = []\n",
    "superclass_entropy = []\n",
    "\n",
    "CLASS_LABELS = ['f1a', 'f2a', 'f2b']\n",
    "SUPERCLASS_LABELS = ['f1', 'f2']\n",
    "CLASS_TO_SUPERCLASS = {0: 0, 1: 1, 2: 1}\n",
    "\n",
    "for i, tree in enumerate(aligned_trees):\n",
    "    class_confidence = [tree.get_node(c).data for c in CLASS_LABELS]\n",
    "    class_confidences.append(class_confidence)\n",
    "    assert np.argmax(class_confidence) == predictions[i]\n",
    "    class_correctness.append(np.argmax(class_confidence) == labels[i])\n",
    "    class_entropy.append(stats.entropy(class_confidence))    \n",
    "    superclass_confidence = [tree.get_node(s).data for s in SUPERCLASS_LABELS]\n",
    "    superclass_confidences.append(superclass_confidence)\n",
    "    superclass_correctness.append(np.argmax(superclass_confidence) == CLASS_TO_SUPERCLASS[labels[i]])\n",
    "    superclass_entropy.append(stats.entropy(superclass_confidence))\n",
    "class_confidences = np.array(class_confidences)\n",
    "class_correctness = np.array(class_correctness)\n",
    "class_entropy = np.array(class_entropy)\n",
    "superclass_confidences = np.array(superclass_confidences)\n",
    "superclass_correctness = np.array(superclass_correctness)\n",
    "superclass_entropy = np.array(superclass_entropy)\n",
    "\n",
    "print('CONFIDENCE, CORRECTNESS, AND ENTROPY FOR EVERY INSTANCE AT THE CLASS AND SUPERCLASS LEVEL')\n",
    "print(f'Class confidence {class_confidences.shape}; all sum to one: {np.all([np.isclose(np.sum(c), 1.0) for c in class_confidences])}')\n",
    "print(f'Class correctness {class_correctness.shape}; equal to accuracy: {np.sum(class_correctness)/len(class_correctness):.2%}')\n",
    "print(f'Class entropy {class_entropy.shape}')\n",
    "print(f'Superclass confidence {superclass_confidences.shape}; all sum to one: {np.all([np.isclose(np.sum(c), 1.0) for c in superclass_confidences])}')\n",
    "print(f'Superclass correctness {superclass_correctness.shape}; superclass accuracy: {np.sum(superclass_correctness)/len(superclass_correctness):.2%}')\n",
    "print(f'Superclass entropy {superclass_entropy.shape}')\n",
    "\n",
    "print(f'ACCURACY -- class-level: {np.sum(class_correctness)/len(class_correctness):.2%}; superclass-level: {np.sum(superclass_correctness)/len(superclass_correctness):.2%}')\n",
    "print(f'ENTROPY --- class-level: {np.mean(class_entropy):.2f}; superclass-level: {np.mean(superclass_entropy):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f732aeb-c5e0-4e64-a130-c24a252fbec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with 6 nodes across 3 levels.\n",
      "root (None)\n",
      "├── f1 (None)\n",
      "│   ├── f1a (None)\n",
      "│   └── f2a (None)\n",
      "└── f2 (None)\n",
      "    └── f2b (None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "misaligned_tree = make_tree(misaligned=True)\n",
    "print(f'Tree with {misaligned_tree.size()} nodes across {misaligned_tree.depth() + 1} levels.')\n",
    "print (show(misaligned_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cfb4215a-405d-4491-9945-80dda48fe980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Measure abstraction alignment by propagating model outputs through the hierarchy\n",
    "misaligned_trees = []\n",
    "for i in range(len(labels)):\n",
    "    tree = propagate(outputs[i], make_tree(misaligned=True))\n",
    "    misaligned_trees.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "366aab4a-7806-41fa-ae1c-be9b40c856c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIDENCE, CORRECTNESS, AND ENTROPY FOR EVERY INSTANCE AT THE CLASS AND SUPERCLASS LEVEL\n",
      "Class confidence (1500, 3); all sum to one: True\n",
      "Class correctness (1500,); equal to accuracy: 84.47%\n",
      "Class entropy (1500,)\n",
      "Superclass confidence (1500, 2); all sum to one: True\n",
      "Superclass correctness (1500,); superclass accuracy: 86.60%\n",
      "Superclass entropy (1500,)\n",
      "ACCURACY -- class-level: 84.47%; superclass-level: 86.60%\n",
      "ENTROPY --- class-level: 0.20; superclass-level: 0.16\n"
     ]
    }
   ],
   "source": [
    "# Compute class and superclass accuracy and entropy\n",
    "from scipy import stats\n",
    "# Confidence vectors, correctness, and entropy for the class and superclass levels for every instance\n",
    "class_confidences = []\n",
    "class_correctness = []\n",
    "class_entropy = []\n",
    "superclass_confidences = []\n",
    "superclass_correctness = []\n",
    "superclass_entropy = []\n",
    "\n",
    "CLASS_LABELS = ['f1a', 'f2a', 'f2b']\n",
    "SUPERCLASS_LABELS = ['f1', 'f2']\n",
    "CLASS_TO_SUPERCLASS = {0: 0, 1: 0, 2: 1}\n",
    "\n",
    "low_entropy = []\n",
    "\n",
    "for i, tree in enumerate(misaligned_trees):\n",
    "    class_confidence = [tree.get_node(c).data for c in CLASS_LABELS]\n",
    "    class_confidences.append(class_confidence)\n",
    "    assert np.argmax(class_confidence) == predictions[i]\n",
    "    class_correctness.append(np.argmax(class_confidence) == labels[i])\n",
    "    class_entropy.append(stats.entropy(class_confidence))\n",
    "    \n",
    "    superclass_confidence = [tree.get_node(s).data for s in SUPERCLASS_LABELS]\n",
    "    superclass_confidences.append(superclass_confidence)\n",
    "    superclass_correctness.append(np.argmax(superclass_confidence) == CLASS_TO_SUPERCLASS[labels[i]])\n",
    "    superclass_entropy.append(stats.entropy(superclass_confidence))\n",
    "    if (stats.entropy(superclass_confidence)) < 0.6:\n",
    "        low_entropy.append(i)\n",
    "        \n",
    "class_confidences = np.array(class_confidences)\n",
    "class_correctness = np.array(class_correctness)\n",
    "class_entropy = np.array(class_entropy)\n",
    "superclass_confidences = np.array(superclass_confidences)\n",
    "superclass_correctness = np.array(superclass_correctness)\n",
    "superclass_entropy = np.array(superclass_entropy)\n",
    "\n",
    "print('CONFIDENCE, CORRECTNESS, AND ENTROPY FOR EVERY INSTANCE AT THE CLASS AND SUPERCLASS LEVEL')\n",
    "print(f'Class confidence {class_confidences.shape}; all sum to one: {np.all([np.isclose(np.sum(c), 1.0) for c in class_confidences])}')\n",
    "print(f'Class correctness {class_correctness.shape}; equal to accuracy: {np.sum(class_correctness)/len(class_correctness):.2%}')\n",
    "print(f'Class entropy {class_entropy.shape}')\n",
    "print(f'Superclass confidence {superclass_confidences.shape}; all sum to one: {np.all([np.isclose(np.sum(c), 1.0) for c in superclass_confidences])}')\n",
    "print(f'Superclass correctness {superclass_correctness.shape}; superclass accuracy: {np.sum(superclass_correctness)/len(superclass_correctness):.2%}')\n",
    "print(f'Superclass entropy {superclass_entropy.shape}')\n",
    "\n",
    "print(f'ACCURACY -- class-level: {np.sum(class_correctness)/len(class_correctness):.2%}; superclass-level: {np.sum(superclass_correctness)/len(superclass_correctness):.2%}')\n",
    "print(f'ENTROPY --- class-level: {np.mean(class_entropy):.2f}; superclass-level: {np.mean(superclass_entropy):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9eed71bb-ef8f-4123-9a4b-f3170fcfc3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP PREDICTED CLASSES:  ['1 (0.90)', '2 (0.10)', '0 (0.00)']\n",
      "PROPAGATED TREE:\n",
      "root (1.00)\n",
      "├── f1 (0.00)\n",
      "│   └── f1a (0.00)\n",
      "└── f2 (1.00)\n",
      "    ├── f2a (0.90)\n",
      "    └── f2b (0.10)\n",
      "\n",
      "[7.444848e-06, 0.8950606, 0.10493199]\n",
      "class entropy: 0.33588094\n",
      "superclass confidence: [7.444848e-06, 0.9999926]\n",
      "superclass entropy: 9.529963e-05\n"
     ]
    }
   ],
   "source": [
    "# An example hierarchy propagation\n",
    "index = 2\n",
    "\n",
    "image = test_set[index][0]\n",
    "image = np.reshape(image, (4, 4, 3)) * 255\n",
    "# plt.imshow(image)\n",
    "plt.imshow(image.astype(int))\n",
    "plt.axis('off')\n",
    "plt.title(f'L: {labels[index]}\\nP: {predictions[index]}')\n",
    "plt.show()\n",
    "\n",
    "top_predictions = np.argsort(outputs[index])[-3:]\n",
    "print('TOP PREDICTED CLASSES: ', [f'{i} ({outputs[index][i]:.2f})' for i in top_predictions][::-1])\n",
    "\n",
    "print('PROPAGATED TREE:')\n",
    "print(show(aligned_trees[index]))\n",
    "\n",
    "tree = aligned_trees[index]\n",
    "class_confidence = [tree.get_node(c).data for c in CLASS_LABELS]\n",
    "print (class_confidence)\n",
    "print ('class entropy: ' + str(stats.entropy(class_confidence))) \n",
    "superclass_confidence = [tree.get_node(s).data for s in SUPERCLASS_LABELS]\n",
    "print ('superclass confidence: ' + str(superclass_confidence))\n",
    "print ('superclass entropy: ' + str(stats.entropy(superclass_confidence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "052960a0-8eb2-41df-a1d8-6965d94e1ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP PREDICTED CLASSES:  ['1 (0.90)', '2 (0.10)', '0 (0.00)']\n",
      "PROPAGATED TREE:\n",
      "root (1.00)\n",
      "├── f1 (0.90)\n",
      "│   ├── f1a (0.00)\n",
      "│   └── f2a (0.90)\n",
      "└── f2 (0.10)\n",
      "    └── f2b (0.10)\n",
      "\n",
      "class entropy: 0.33588094\n",
      "[0.89506805, 0.10493199]\n",
      "superclass entropy: 0.3357864\n"
     ]
    }
   ],
   "source": [
    "# An example hierarchy propagation\n",
    "index = 2\n",
    "\n",
    "image = test_set[index][0]\n",
    "image = np.reshape(image, (4, 4, 3)) * 255\n",
    "# plt.imshow(image)\n",
    "plt.imshow(image.astype(int))\n",
    "plt.axis('off')\n",
    "plt.title(f'L: {labels[index]}\\nP: {predictions[index]}')\n",
    "plt.show()\n",
    "\n",
    "top_predictions = np.argsort(outputs[index])[-3:]\n",
    "print('TOP PREDICTED CLASSES: ', [f'{i} ({outputs[index][i]:.2f})' for i in top_predictions][::-1])\n",
    "\n",
    "print('PROPAGATED TREE:')\n",
    "print(show(misaligned_trees[index]))\n",
    "\n",
    "tree = misaligned_trees[index]\n",
    "class_confidence = [tree.get_node(c).data for c in CLASS_LABELS]\n",
    "# print (class_confidence)\n",
    "print ('class entropy: ' + str(stats.entropy(class_confidence))) \n",
    "superclass_confidence = [tree.get_node(s).data for s in SUPERCLASS_LABELS]\n",
    "print (superclass_confidence)\n",
    "print ('superclass entropy: ' + str(stats.entropy(superclass_confidence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9178f-7b1c-408b-9939-ade653310f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
