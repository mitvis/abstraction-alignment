{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdaffde-cc48-4625-9ff5-e7ae2631cbd1",
   "metadata": {},
   "source": [
    "# Abstraction Alignment to Benchmark Language Models\n",
    "We expand the S-TEST metrics (https://github.com/jeffhj/S-TEST) using abstraction alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0da3f9-862a-4a2e-9737-7b35da57f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afdbc3d5-fdf5-4ed7-bbf0-f7f7aa942118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bafcd3-6f7c-401d-a786-5e8c22ceef82",
   "metadata": {},
   "source": [
    "### Load the S-TEST dataset and model results\n",
    "In order to get results, first run `python S-TEST/scripts/run_experiments.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3274de5f-ac44-4c5a-a16b-e934fb704366",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'S-TEST/data/S-TEST/'\n",
    "RESULTS_DIR = 'S-TEST/output/results/'\n",
    "\n",
    "MODELS = [\n",
    "    'bert_base', \n",
    "    'bert_large', \n",
    "    'roberta.base', \n",
    "    'roberta.large', \n",
    "    'gpt2',\n",
    "]\n",
    "TASKS = [\n",
    "    {'name': 'occupation', 'id': 'P106', 'up_fn': 'hypernyms', 'down_fn': 'hyponyms', 'root': wn.synset('person.n.01')},\n",
    "    {'name': 'location', 'id': 'P131', 'up_fn': 'part_holonyms', 'down_fn': 'part_meronyms', 'root': None},\n",
    "    {'name': 'place of birth', 'id': 'P19', 'up_fn': 'part_holonyms', 'down_fn': 'part_meronyms', 'root': None},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b534ce-197e-4ac9-acda-cde1f1221b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_instances(task_id):\n",
    "    with open(os.path.join(DATA_DIR, f'{task_id}.jsonl'), 'r') as f:\n",
    "        data = [json.loads(l) for l in f]\n",
    "    instances = [(d['sub_label'], d['obj_label'], d['obj2_label']) for d in data]\n",
    "    return instances\n",
    "\n",
    "def load_data(task_id):\n",
    "    \"\"\"Load the data instances for a task_id. There can be duplicates, but we\n",
    "    handle them the same way the S-TEST repo does.\"\"\"\n",
    "    data = {}\n",
    "    with open(os.path.join(DATA_DIR, f'{task_id}.jsonl'), 'r') as f:\n",
    "        for line in f:\n",
    "            datum = json.loads(line)\n",
    "            data[datum['sub_label']] = datum\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a206190-ce11-4e7c-8b14-097475b3fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999 instances for occupation prediciton task.\n",
      "Example data:\n",
      "{'sub_uri': 'Q39074561', 'sub_label': 'Joe Carter', 'obj_uri': 'Q1371925', 'obj_label': 'announcer', 'obj_value': 2.0, 'obj2_uri': 'Q1930187', 'obj2_label': 'journalist', 'obj2_value': 3.0, 'predicate_id': 'P106'}\n"
     ]
    }
   ],
   "source": [
    "task = TASKS[0]\n",
    "model = MODELS[0]\n",
    "\n",
    "data = load_data(task['id'])\n",
    "print(f\"{len(data)} instances for {task['name']} prediciton task.\")\n",
    "print(f\"Example data:\")\n",
    "print(data[list(data.keys())[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7be51d-c8d6-46b5-ab9b-4ce04ec7a592",
   "metadata": {},
   "source": [
    "### Compute model accuracy and S-TEST p_r specificity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c1fb9b-3e79-4bed-a257-5a0e5482b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_results(model_name, task_id):\n",
    "    with open(os.path.join(RESULTS_DIR, model_name, task_id, 'result.pkl'), 'rb') as f:\n",
    "        results = pickle.load(f)['list_of_results']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8de27d-4ac4-44df-b5ab-386ea3359234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 predictions for bert_base on occupation prediciton task.\n",
      "Predictions for results[0] sum to 0.8970748439562531\n",
      "Computed probabilities for 18173 words.\n"
     ]
    }
   ],
   "source": [
    "results = load_model_results(model, task['id'])\n",
    "print(f\"{len(results)} predictions for {model} on {task['name']} prediciton task.\")\n",
    "print(f\"Predictions for results[0] sum to {np.sum([np.exp(w['log_prob']) for w in results[0]['masked_topk']['topk']])}\")\n",
    "print(f\"Computed probabilities for {len(results[0]['masked_topk']['topk'])} words.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecde337-5021-4cc8-80da-18f3986e74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pr(results, data):\n",
    "    specific = 0\n",
    "    for result in results:\n",
    "        subject = result['sample']['sub_label']\n",
    "        data_instance = data[subject]\n",
    "        specific_label = data_instance['obj_label']\n",
    "        coarse_label = data_instance['obj2_label']\n",
    "        for token in result['masked_topk']['topk']:\n",
    "            if token['token_word_form'] == specific_label:\n",
    "                specific += 1\n",
    "                break\n",
    "            if token['token_word_form'] == coarse_label:\n",
    "                break\n",
    "    return specific / len(results)\n",
    "\n",
    "def compute_accuracy(results, data, k=1):\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        subject = result['sample']['sub_label']\n",
    "        data_instance = data[subject]\n",
    "        label = data_instance['obj_label']\n",
    "        topk_words = [t['token_word_form'] for t in result['masked_topk']['topk'][:k]]\n",
    "        if label in topk_words:\n",
    "            correct += 1\n",
    "    return correct / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b2906d-f3ad-4a01-b267-b574ce01581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base occupation prediction acc@1 = 0.32%; acc@10 = 28.44%\n"
     ]
    }
   ],
   "source": [
    "accuracy_1 = compute_accuracy(results, data, k=1)\n",
    "accuracy_10 = compute_accuracy(results, data, k=10)\n",
    "print(f\"{model} {task['name']} prediction acc@1 = {accuracy_1:.2%}; acc@10 = {accuracy_10:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79694a24-2fbc-4674-829b-543d7f27ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base occupation prediction pr = 70.46%\n"
     ]
    }
   ],
   "source": [
    "pr = compute_pr(results, data)\n",
    "print(f\"{model} {task['name']} prediction pr = {pr:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b101cbe-7c2e-4ccd-875a-34168c553c19",
   "metadata": {},
   "source": [
    "### Compute abstraction specificity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e15a8-e272-4560-b874-172dcfb1d721",
   "metadata": {},
   "source": [
    "#### Get related words from WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8772348e-dc9b-4736-bbbc-5e4ac9caa542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_words(synset, traversal_fn_name, root=None, include_self=True):\n",
    "    traversal_fn = getattr(synset, traversal_fn_name)\n",
    "    words = set([])\n",
    "    if include_self:\n",
    "        words.add(synset.name().split('.')[0])\n",
    "    if (root is not None and synset == root) or len(traversal_fn()) == 0:\n",
    "        return words\n",
    "    for word in traversal_fn():\n",
    "        next_words = get_related_words(word, traversal_fn_name, root)\n",
    "        words.update(next_words)\n",
    "    return words\n",
    "\n",
    "def get_abstraction_graph(task):\n",
    "    with open(os.path.join(DATA_DIR, f\"{task['id']}_synsets.json\"), 'r') as f:\n",
    "        label_synsets = json.load(f)\n",
    "    label_to_synset = {label: wn.synset(synset) for label, synset in label_synsets if synset is not None}\n",
    "    abstraction_graph = {}\n",
    "    for label, synset in label_to_synset.items():\n",
    "        if synset in abstraction_graph: \n",
    "            continue\n",
    "        children = get_related_words(synset, task['down_fn'], root=task['root'], include_self=True)\n",
    "        children.add(label)\n",
    "        parents = get_related_words(synset, task['up_fn'], root=task['root'], include_self=False)\n",
    "        abstraction_graph[label] = {\n",
    "            'children': children,\n",
    "            'parents': parents\n",
    "        }\n",
    "    return abstraction_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b350ab5-9d50-4b04-a15f-1904bf3962fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3507604/1756374758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabstraction_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_abstraction_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Related words for {len(abstraction_graph)} synsets.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Avg num children = {np.mean([len(w['children']) for w in abstraction_graph.values()])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Avg num parents = {np.mean([len(w['parents']) for w in abstraction_graph.values()])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstraction_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-->'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstraction_graph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstraction_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3507604/2069573659.py\u001b[0m in \u001b[0;36mget_abstraction_graph\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_abstraction_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{task['id']}_synsets.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlabel_synsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlabel_to_synset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_synsets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "abstraction_graph = get_abstraction_graph(task['id'])\n",
    "print(f\"Related words for {len(abstraction_graph)} synsets.\")\n",
    "print(f\"Avg num children = {np.mean([len(w['children']) for w in abstraction_graph.values()])}\")\n",
    "print(f\"Avg num parents = {np.mean([len(w['parents']) for w in abstraction_graph.values()])}\")\n",
    "print(list(abstraction_graph.keys())[0], '-->', abstraction_graph[list(abstraction_graph.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c263b9b-e37a-46a9-b031-32ca1069f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_words = {'children': set([]), 'parents': set([])}\n",
    "for words in abstraction_graph.values():\n",
    "    task_words['children'].update(words['children'])\n",
    "    task_words['parents'].update(words['parents'])\n",
    "print(f\"{len(task_words['children']) + len(task_words['parents'])} words related to the task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89af21-5565-4efa-9951-4ede56df6fe5",
   "metadata": {},
   "source": [
    "### Compute abstraction alignment specificity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b67022a-e9cc-4d79-8678-dda97e503544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_s --> how often a specific word is preferred to a general word\n",
    "def compute_ps(results, data, abstraction_graph, agg_fn=np.max):\n",
    "    prefers_specific = 0\n",
    "    num_instances = 0\n",
    "    for result in results:\n",
    "        subject = result['sample']['sub_label']\n",
    "        label = data[subject]['obj_label']\n",
    "        if label not in abstraction_graph:\n",
    "            continue\n",
    "        specific_word_probs = []\n",
    "        general_word_probs = []\n",
    "        # print('children: ', abstraction_graph[label]['children'])\n",
    "        # print('parents: ', abstraction_graph[label]['parents'])\n",
    "        for token in result['masked_topk']['topk']:\n",
    "            if token['token_word_form'] in abstraction_graph[label]['children']:\n",
    "                specific_word_probs.append(np.exp(token['log_prob']))\n",
    "            if token['token_word_form'] in abstraction_graph[label]['parents']:\n",
    "                general_word_probs.append(np.exp(token['log_prob']))\n",
    "        \n",
    "        if len(specific_word_probs) == 0 and len(general_word_probs) == 0:\n",
    "            continue # no related words are in the vocab, so can't copute ps\n",
    "        num_instances += 1\n",
    "        \n",
    "        if len(specific_word_probs) == 0 and len(general_word_probs) > 0:\n",
    "            continue # specific words not in the vocab, prefer general\n",
    "        elif len(specific_word_probs) > 0 and len(general_word_probs) == 0:\n",
    "            prefers_specific += 1 # general words not in the vocab, prefer specific\n",
    "            continue\n",
    "        elif agg_fn(specific_word_probs) >= agg_fn(general_word_probs):\n",
    "            prefers_specific += 1\n",
    "        \n",
    "    return prefers_specific / num_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318bf877-1cba-4f8b-a3c7-9586072e7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_max = compute_ps(results, data, abstraction_graph, agg_fn=np.max)\n",
    "print(f\"{model} {task['name']} prediction ps_max = {ps_max:.2%}\")\n",
    "\n",
    "ps_mean = compute_ps(results, data, abstraction_graph, agg_fn=np.mean)\n",
    "print(f\"{model} {task['name']} prediction ps_mean = {ps_mean:.2%}\")\n",
    "\n",
    "ps_sum = compute_ps(results, data, abstraction_graph, agg_fn=np.sum)\n",
    "print(f\"{model} {task['name']} prediction ps_sum = {ps_sum:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac5f3ae-9753-4ed6-855c-670b01c0ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_t --> how often a related word is prefferred to a topic word\n",
    "def compute_pt(results, data, abstraction_graph, task_words, agg_fn=np.max):\n",
    "    prefers_specific = 0\n",
    "    num_instances = 0\n",
    "    for result in results:\n",
    "        subject = result['sample']['sub_label']\n",
    "        label = data[subject]['obj_label']\n",
    "        if label not in abstraction_graph:\n",
    "            continue\n",
    "        specific_word_probs = []\n",
    "        task_word_probs = []\n",
    "        for token in result['masked_topk']['topk']:\n",
    "            token_word = token['token_word_form']\n",
    "            if token_word in abstraction_graph[label]['children'] or token_word in abstraction_graph[label]['parents']:\n",
    "                specific_word_probs.append(np.exp(token['log_prob']))\n",
    "            if token_word in task_words:\n",
    "                task_word_probs.append(np.exp(token['log_prob']))\n",
    "                \n",
    "        if len(specific_word_probs) == 0 and len(task_word_probs) == 0:\n",
    "            continue # no related words are in the vocab, so can't copute ps\n",
    "        num_instances += 1\n",
    "        \n",
    "        if len(specific_word_probs) == 0 and len(task_word_probs) > 0:\n",
    "            continue # specific words not in the vocab, prefer topic\n",
    "        elif len(specific_word_probs) > 0 and len(task_word_probs) == 0:\n",
    "            prefers_specific += 1 # topic words not in the vocab, prefer specific\n",
    "            continue\n",
    "        elif agg_fn(specific_word_probs) >= agg_fn(task_word_probs):\n",
    "            prefers_specific += 1\n",
    "    return prefers_specific / num_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd860b-e460-4a89-8204-e2bc8c677662",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_max = compute_pt(results, data, abstraction_graph, topic_words, agg_fn=np.max)\n",
    "print(f\"{model} {task['name']} prediction pt_max = {pt_max:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6469e30-4109-41c3-85a4-89bf24863dc7",
   "metadata": {},
   "source": [
    "### Compute metrics for all tasks and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00e27583-e32a-41c6-a460-8944220e3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(tasks, models):\n",
    "    for task in tasks:\n",
    "        print(f\"TASK {task['id']}: {task['name']} prediction\")\n",
    "        data = load_data(task['id'])\n",
    "        abstraction_graph = get_abstraction_graph(task)        \n",
    "        task_words = set([])\n",
    "        for words in abstraction_graph.values():\n",
    "            task_words.update(words['children'])\n",
    "            task_words.update(words['parents'])\n",
    "        for model in models:\n",
    "            print(f\"--- MODEL {model}\")\n",
    "            results = load_model_results(model, task['id'])\n",
    "            \n",
    "            # accuracy_1 = compute_accuracy(results, data, k=1)\n",
    "            # print(f'------ acc@1  = {accuracy_1:.2%}')\n",
    "\n",
    "            accuracy_10 = compute_accuracy(results, data, k=10)\n",
    "            print(f'------ acc@10 = {accuracy_10:.2%}')\n",
    "            \n",
    "            pr = compute_pr(results, data)\n",
    "            print(f'------ pr     = {pr:.2%}')\n",
    "            \n",
    "            ps_max = compute_ps(results, data, abstraction_graph, agg_fn=np.max)\n",
    "            print(f\"------ ps_max = {ps_max:.2%}\")\n",
    "\n",
    "#             ps_mean = compute_ps(results, data, abstraction_graph, agg_fn=np.mean)\n",
    "#             print(f\"------ ps_avg = {ps_mean:.2%}\")\n",
    "\n",
    "#             ps_sum = compute_ps(results, data, abstraction_graph, agg_fn=np.sum)\n",
    "#             print(f\"------ ps_sum = {ps_sum:.2%}\")\n",
    "            \n",
    "            pt_max = compute_pt(results, data, abstraction_graph, task_words, agg_fn=np.max)\n",
    "            print(f\"------ pt_max = {pt_max:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad9e5bf-0d6e-4bb8-86fc-b79cc778b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK P106: occupation prediction\n",
      "--- MODEL bert_base\n",
      "------ acc@10 = 28.44%\n",
      "------ pr     = 70.46%\n",
      "------ ps_max = 79.02%\n",
      "------ pt_max = 0.68%\n",
      "--- MODEL bert_large\n",
      "------ acc@10 = 22.14%\n",
      "------ pr     = 71.76%\n",
      "------ ps_max = 82.40%\n",
      "------ pt_max = 1.16%\n",
      "--- MODEL roberta.base\n",
      "------ acc@10 = 24.50%\n",
      "------ pr     = 61.80%\n",
      "------ ps_max = 78.98%\n",
      "------ pt_max = 7.51%\n",
      "--- MODEL roberta.large\n",
      "------ acc@10 = 22.44%\n",
      "------ pr     = 71.44%\n",
      "------ ps_max = 82.38%\n",
      "------ pt_max = 7.97%\n",
      "--- MODEL gpt2\n",
      "------ acc@10 = 16.10%\n",
      "------ pr     = 57.28%\n",
      "------ ps_max = 51.93%\n",
      "------ pt_max = 16.82%\n",
      "TASK P131: location prediction\n",
      "--- MODEL bert_base\n",
      "------ acc@10 = 43.16%\n",
      "------ pr     = 49.09%\n",
      "------ ps_max = 97.52%\n",
      "------ pt_max = 23.04%\n",
      "--- MODEL bert_large\n",
      "------ acc@10 = 45.64%\n",
      "------ pr     = 42.36%\n",
      "------ ps_max = 98.21%\n",
      "------ pt_max = 27.44%\n",
      "--- MODEL roberta.base\n",
      "------ acc@10 = 36.59%\n",
      "------ pr     = 49.99%\n",
      "------ ps_max = 98.54%\n",
      "------ pt_max = 17.90%\n",
      "--- MODEL roberta.large\n",
      "------ acc@10 = 39.05%\n",
      "------ pr     = 43.28%\n",
      "------ ps_max = 98.69%\n",
      "------ pt_max = 22.42%\n",
      "--- MODEL gpt2\n",
      "------ acc@10 = 17.02%\n",
      "------ pr     = 48.25%\n",
      "------ ps_max = 66.59%\n",
      "------ pt_max = 13.48%\n",
      "TASK P19: place of birth prediction\n",
      "--- MODEL bert_base\n",
      "------ acc@10 = 41.42%\n",
      "------ pr     = 60.68%\n",
      "------ ps_max = 99.94%\n",
      "------ pt_max = 24.50%\n",
      "--- MODEL bert_large\n",
      "------ acc@10 = 42.14%\n",
      "------ pr     = 56.52%\n",
      "------ ps_max = 99.75%\n",
      "------ pt_max = 25.92%\n",
      "--- MODEL roberta.base\n",
      "------ acc@10 = 28.97%\n",
      "------ pr     = 54.48%\n",
      "------ ps_max = 100.00%\n",
      "------ pt_max = 20.42%\n",
      "--- MODEL roberta.large\n",
      "------ acc@10 = 23.21%\n",
      "------ pr     = 42.16%\n",
      "------ ps_max = 99.92%\n",
      "------ pt_max = 22.48%\n",
      "--- MODEL gpt2\n",
      "------ acc@10 = 33.27%\n",
      "------ pr     = 59.72%\n",
      "------ ps_max = 98.79%\n",
      "------ pt_max = 19.59%\n"
     ]
    }
   ],
   "source": [
    "main(TASKS, MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732c258-2195-4565-b31c-3ed3c6f6ae57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
