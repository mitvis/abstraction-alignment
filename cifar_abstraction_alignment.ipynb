{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d186ff-ec39-4566-ab49-4be34aecfc2a",
   "metadata": {},
   "source": [
    "# Abstraction Alignment to Interpret a CIFAR-100 Model\n",
    "We apply abstraction alignment to interpret a CIFAR-100 image classification model using the CIFAR-100 class-superclass hierarchy as the human abstraction graph. This example is loosly based on the Interpreting Image Model Behavior Beyond Misclassification case study in the abstraction alignment paper.\n",
    "\n",
    "In this notebook, we train and evaluate a ResNet20 on CIFAR-100. We use the abstraction alignment methodology to aggregate and report the model's abstraction match and qualitatively analyze common \"types\" of abstraction (mis)alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c600f05-c1a4-4bb7-b493-31b9f5dc96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "80be5757-c011-490a-9928-8f91b451f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "from itertools import combinations\n",
    "\n",
    "import metrics\n",
    "import cifar\n",
    "import cifar_util\n",
    "import cifar_train\n",
    "import cifar_metadata\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe1308-c6a1-4f0d-b7dc-cc023a987e00",
   "metadata": {},
   "source": [
    "## CIFAR-100 Model and Dataset\n",
    "First, we load the CIFAR-100 dataset and train a ResNet20 on it. This is the model we will inspect with abstraction alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbf4bc3-03d6-4ce0-85fd-181c7ad111ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined paths -- TODO: update with your own\n",
    "MODEL_PATH = 'cifar/'\n",
    "CIFAR_DIR = '/nobackup/users/aboggust/data/cifar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb68d8ff-7f5c-4ec3-ac8a-e2269d00f094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained CIFAR-100 model from: cifar/resnet20/checkpoints/checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "# Train a ResNet20 on CIFAR-100\n",
    "batch_size = 128\n",
    "data_augmentation = True\n",
    "epochs = 200\n",
    "architecture = 'resnet20'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = os.path.join(MODEL_PATH, architecture, 'checkpoints', 'checkpoint.pt')\n",
    "if os.path.isfile(checkpoint):\n",
    "    print(f'Loading trained CIFAR-100 model from: {checkpoint}')\n",
    "    model = cifar_util.load_model(architecture)\n",
    "    model.load_state_dict(torch.load(checkpoint))\n",
    "else:\n",
    "    print(f'Training CIFAR-100 model')\n",
    "    model = cifar_train.train(\n",
    "        architecture, \n",
    "        batch_size, \n",
    "        epochs, \n",
    "        CIFAR_DIR,\n",
    "        MODEL_PATH,\n",
    "        data_augmentation\n",
    "    )\n",
    "    \n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e0388f-bf30-4361-8316-7d772b42b10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-100 dataset for exploration\n",
    "train_loader, test_loader = cifar_util.load_dataset(CIFAR_DIR, \n",
    "                                                    data_augmentation,\n",
    "                                                    batch_size)\n",
    "test_dataset = test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86afa4b2-33d7-4f75-b2cc-f0e45794e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute model outputs on test instances\n",
    "labels = []\n",
    "outputs = []\n",
    "for i, (image, label) in enumerate(tqdm(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        images = image.to(device)\n",
    "    labels.extend(label.numpy())\n",
    "    output = model(images)\n",
    "    output = torch.nn.functional.softmax(output, dim=1).detach().cpu().numpy()\n",
    "    outputs.append(output)\n",
    "outputs = np.vstack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b313015-bd94-40a2-be71-bb35cdde4358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL STATS:\n",
      "Accuracy: 67.68%\n",
      "Mean prediction confidence: 0.78\n",
      "Mean prediction confidence (correct): 0.87\n",
      "Mean prediction confidence (incorrect): 0.59\n"
     ]
    }
   ],
   "source": [
    "# Print model performance statistics\n",
    "predictions = [np.argmax(output) for output in outputs]\n",
    "correctness = [label == predictions[i] for i, label in enumerate(labels)]\n",
    "correct_inds = [i for i, label in enumerate(labels) if label == predictions[i]]\n",
    "incorrect_inds = [i for i, label in enumerate(labels) if label != predictions[i]]\n",
    "print(f'MODEL STATS:')\n",
    "print(f'Accuracy: {len(correct_inds) / len(labels):.2%}')\n",
    "print(f'Mean prediction confidence: {np.mean([np.max(output) for output in outputs]):.2f}')\n",
    "print(f'Mean prediction confidence (correct): {np.mean([np.max(outputs[i]) for i in correct_inds]):.2f}')\n",
    "print(f'Mean prediction confidence (incorrect): {np.mean([np.max(outputs[i]) for i in incorrect_inds]):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2279f9f2-a94d-4a79-9650-d329545c22d2",
   "metadata": {},
   "source": [
    "## Compute Abstraction Alignment\n",
    "We use abstraction alignment to analyze how well the human abstractions account for the model's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10298861-174d-4e19-ab72-4337314aa2e7",
   "metadata": {},
   "source": [
    "### Load the human abstraction graph (i.e., the CIFAR-100 class and superclass hiearchy)\n",
    "The human abstraction graph represents human concepts and the relationships between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd9a76c9-b727-49c1-a22b-1c7d6bc00eb6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 tree with 121 nodes across 3 levels.\n",
      "root (None)\n",
      "├── aquatic_mammals (None)\n",
      "│   ├── beaver (None)\n",
      "│   ├── dolphin (None)\n",
      "│   ├── otter (None)\n",
      "│   ├── seal (None)\n",
      "│   └── whale (None)\n",
      "├── fish (None)\n",
      "│   ├── aquarium_fish (None)\n",
      "│   ├── flatfish (None)\n",
      "│   ├── ray (None)\n",
      "│   ├── shark (None)\n",
      "│   └── trout (None)\n",
      "├── flowers (None)\n",
      "│   ├── orchid (None)\n",
      "│   ├── poppy (None)\n",
      "│   ├── rose (None)\n",
      "│   ├── sunflower (None)\n",
      "│   └── tulip (None)\n",
      "├── food_containers (None)\n",
      "│   ├── bottle (None)\n",
      "│   ├── bowl (None)\n",
      "│   ├── can (None)\n",
      "│   ├── cup (None)\n",
      "│   └── plate (None)\n",
      "├── fruit_and_vegetables (None)\n",
      "│   ├── apple (None)\n",
      "│   ├── mushroom (None)\n",
      "│   ├── orange (None)\n",
      "│   ├── pear (None)\n",
      "│   └── sweet_pepper (None)\n",
      "├── household_electrical_devices (None)\n",
      "│   ├── clock (None)\n",
      "│   ├── keyboard (None)\n",
      "│   ├── lamp (None)\n",
      "│   ├── telephone (None)\n",
      "│   └── television (None)\n",
      "├── household_furniture (None)\n",
      "│   ├── bed (None)\n",
      "│   ├── chair (None)\n",
      "│   ├── couch (None)\n",
      "│   ├── table (None)\n",
      "│   └── wardrobe (None)\n",
      "├── insects (None)\n",
      "│   ├── bee (None)\n",
      "│   ├── beetle (None)\n",
      "│   ├── butterfly (None)\n",
      "│   ├── caterpillar (None)\n",
      "│   └── cockroach (None)\n",
      "├── large_carnivores (None)\n",
      "│   ├── bear (None)\n",
      "│   ├── leopard (None)\n",
      "│   ├── lion (None)\n",
      "│   ├── tiger (None)\n",
      "│   └── wolf (None)\n",
      "├── large_man-made_outdoor_things (None)\n",
      "│   ├── bridge (None)\n",
      "│   ├── castle (None)\n",
      "│   ├── house (None)\n",
      "│   ├── road (None)\n",
      "│   └── skyscraper (None)\n",
      "├── large_natural_outdoor_scenes (None)\n",
      "│   ├── cloud (None)\n",
      "│   ├── forest (None)\n",
      "│   ├── mountain (None)\n",
      "│   ├── plain (None)\n",
      "│   └── sea (None)\n",
      "├── large_omnivores_and_herbivores (None)\n",
      "│   ├── camel (None)\n",
      "│   ├── cattle (None)\n",
      "│   ├── chimpanzee (None)\n",
      "│   ├── elephant (None)\n",
      "│   └── kangaroo (None)\n",
      "├── medium_mammals (None)\n",
      "│   ├── fox (None)\n",
      "│   ├── porcupine (None)\n",
      "│   ├── possum (None)\n",
      "│   ├── raccoon (None)\n",
      "│   └── skunk (None)\n",
      "├── non-insect_invertebrates (None)\n",
      "│   ├── crab (None)\n",
      "│   ├── lobster (None)\n",
      "│   ├── snail (None)\n",
      "│   ├── spider (None)\n",
      "│   └── worm (None)\n",
      "├── people (None)\n",
      "│   ├── baby (None)\n",
      "│   ├── boy (None)\n",
      "│   ├── girl (None)\n",
      "│   ├── man (None)\n",
      "│   └── woman (None)\n",
      "├── reptiles (None)\n",
      "│   ├── crocodile (None)\n",
      "│   ├── dinosaur (None)\n",
      "│   ├── lizard (None)\n",
      "│   ├── snake (None)\n",
      "│   └── turtle (None)\n",
      "├── small_mammals (None)\n",
      "│   ├── hamster (None)\n",
      "│   ├── mouse (None)\n",
      "│   ├── rabbit (None)\n",
      "│   ├── shrew (None)\n",
      "│   └── squirrel (None)\n",
      "├── trees (None)\n",
      "│   ├── maple_tree (None)\n",
      "│   ├── oak_tree (None)\n",
      "│   ├── palm_tree (None)\n",
      "│   ├── pine_tree (None)\n",
      "│   └── willow_tree (None)\n",
      "├── vehicles_1 (None)\n",
      "│   ├── bicycle (None)\n",
      "│   ├── bus (None)\n",
      "│   ├── motorcycle (None)\n",
      "│   ├── pickup_truck (None)\n",
      "│   └── train (None)\n",
      "└── vehicles_2 (None)\n",
      "    ├── lawn_mower (None)\n",
      "    ├── rocket (None)\n",
      "    ├── streetcar (None)\n",
      "    ├── tank (None)\n",
      "    └── tractor (None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = cifar.make_tree()\n",
    "print(f'CIFAR-100 tree with {tree.size()} nodes across {tree.depth() + 1} levels.')\n",
    "print(cifar.show(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbb14d-1115-4cd1-84bc-eb13163d7f50",
   "metadata": {},
   "source": [
    "### Create the model's fitted abstractions\n",
    "The model's fitted abstractions are a weighted version of the abstraction graph for each model decision. The value of each node represents the model's confidence in that concept. If it is a leaf node, then the value is the model's confidence in that decision. If it is an internal node, then the value is the sum of the model's confidence across its reacahble leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20e03894-e9a2-4367-834b-96e457a30723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:17<00:00, 128.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create the model's fitted abstractions for each instance by propagating model outputs through the abstraction graph\n",
    "fitted_abstractions = []\n",
    "for i in tqdm(range(len(labels))):\n",
    "    tree = cifar.propagate(outputs[i], cifar.make_tree())\n",
    "    fitted_abstractions.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5319d3d7-c975-4dbb-9c3c-aed2e4f8dfc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP PREDICTED CLASSES:  ['train (0.37)', 'road (0.18)', 'spider (0.17)']\n",
      "FITTED ABSTRACTION:\n",
      "root (1.00)\n",
      "├── aquatic_mammals (0.03)\n",
      "│   ├── seal (0.02)\n",
      "├── household_furniture (0.01)\n",
      "│   ├── couch (0.01)\n",
      "├── insects (0.03)\n",
      "│   └── cockroach (0.03)\n",
      "├── large_man-made_outdoor_things (0.20)\n",
      "│   ├── bridge (0.01)\n",
      "│   ├── road (0.18)\n",
      "│   └── skyscraper (0.01)\n",
      "├── large_natural_outdoor_scenes (0.01)\n",
      "├── large_omnivores_and_herbivores (0.01)\n",
      "├── non-insect_invertebrates (0.17)\n",
      "│   ├── spider (0.17)\n",
      "├── people (0.01)\n",
      "│   ├── girl (0.01)\n",
      "├── trees (0.12)\n",
      "│   ├── palm_tree (0.12)\n",
      "├── vehicles_1 (0.37)\n",
      "│   └── train (0.37)\n",
      "└── vehicles_2 (0.04)\n",
      "    ├── streetcar (0.04)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show an example fitted abstraction\n",
    "index = 0\n",
    "\n",
    "image = test_dataset[index][0].permute(1, 2, 0)\n",
    "plt.imshow(cifar_util.unnorm_cifar_image(image))\n",
    "plt.axis('off')\n",
    "plt.title(f'Label: {cifar_metadata.CLASS_LABELS[labels[index]]}\\nPred: {cifar_metadata.CLASS_LABELS[predictions[index]]}')\n",
    "plt.show()\n",
    "\n",
    "top_predictions = np.argsort(outputs[index])[-3:]\n",
    "print('TOP PREDICTED CLASSES: ', [f'{cifar_metadata.CLASS_LABELS[i]} ({outputs[index][i]:.2f})' for i in top_predictions][::-1])\n",
    "\n",
    "print('FITTED ABSTRACTION:')\n",
    "print(cifar.show(fitted_abstractions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838c642-092d-4484-980c-efa473037f5c",
   "metadata": {},
   "source": [
    "### Abstraction Match\n",
    "Abstraction match measures how much moving up one level of abstraction reduces the model's entropy. If the abstraction match is high (e.g., a lot of entropy is reduced), that is a signal that the model has learned those abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7eae3ec9-35d9-42ff-bab4-59fa57eeeb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:20<00:00,  1.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-eb32ddda649b428d9de64e33e7690f60.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-eb32ddda649b428d9de64e33e7690f60.vega-embed details,\n",
       "  #altair-viz-eb32ddda649b428d9de64e33e7690f60.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-eb32ddda649b428d9de64e33e7690f60\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-eb32ddda649b428d9de64e33e7690f60\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-eb32ddda649b428d9de64e33e7690f60\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-6396fcf7d066a9c0e7cfeccd6da02f5b\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"x\": {\"field\": \"concept\", \"sort\": \"-y\", \"type\": \"nominal\"}, \"y\": {\"field\": \"abstraction match\", \"type\": \"quantitative\"}}, \"title\": \"Abstraction Match per Superclass\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-6396fcf7d066a9c0e7cfeccd6da02f5b\": [{\"concept\": \"people\", \"abstraction match\": 0.6951291561126709}, {\"concept\": \"trees\", \"abstraction match\": 0.666723906993866}, {\"concept\": \"flowers\", \"abstraction match\": 0.5305652618408203}, {\"concept\": \"household_furniture\", \"abstraction match\": 0.4494735300540924}, {\"concept\": \"fruit_and_vegetables\", \"abstraction match\": 0.4099380075931549}, {\"concept\": \"large_natural_outdoor_scenes\", \"abstraction match\": 0.40929871797561646}, {\"concept\": \"food_containers\", \"abstraction match\": 0.39550936222076416}, {\"concept\": \"aquatic_mammals\", \"abstraction match\": 0.38348305225372314}, {\"concept\": \"small_mammals\", \"abstraction match\": 0.36819955706596375}, {\"concept\": \"large_man-made_outdoor_things\", \"abstraction match\": 0.35700759291648865}, {\"concept\": \"fish\", \"abstraction match\": 0.3563827574253082}, {\"concept\": \"insects\", \"abstraction match\": 0.33431577682495117}, {\"concept\": \"large_omnivores_and_herbivores\", \"abstraction match\": 0.3260774612426758}, {\"concept\": \"household_electrical_devices\", \"abstraction match\": 0.3251038193702698}, {\"concept\": \"vehicles_1\", \"abstraction match\": 0.32439184188842773}, {\"concept\": \"large_carnivores\", \"abstraction match\": 0.3212800621986389}, {\"concept\": \"reptiles\", \"abstraction match\": 0.2922455966472626}, {\"concept\": \"medium_mammals\", \"abstraction match\": 0.29131749272346497}, {\"concept\": \"non-insect_invertebrates\", \"abstraction match\": 0.28360676765441895}, {\"concept\": \"vehicles_2\", \"abstraction match\": 0.2339886575937271}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute level-1 abstraction match aggregated per level-1 concept\n",
    "instance_per_concept = {}\n",
    "for i, label in enumerate(labels):\n",
    "    label_concept = cifar_metadata.CLASS_TO_SUPERCLASS[label]\n",
    "    if label_concept not in instance_per_concept:\n",
    "        instance_per_concept[label_concept] = set([])\n",
    "    instance_per_concept[label_concept].add(i)\n",
    "\n",
    "# Compute abstraction match per leve-1 concept\n",
    "level_1_concept_abstraction_match = {}\n",
    "for concept, instances in tqdm(instance_per_concept.items()):\n",
    "    instance_fitted_abstractions = [fitted_abstraction for i, fitted_abstraction in enumerate(fitted_abstractions) if i in instances]\n",
    "    match = metrics.abstraction_match(instance_fitted_abstractions, 1)\n",
    "    level_1_concept_abstraction_match[concept] = match\n",
    "    \n",
    "# Plot abstraction match\n",
    "ordered_concepts = sorted(level_1_concept_abstraction_match.keys(), key=lambda c: level_1_concept_abstraction_match[c], reverse=True)\n",
    "df = pd.DataFrame.from_dict({\n",
    "    'concept': [cifar_metadata.SUPERCLASS_LABELS[concept] for concept in ordered_concepts],\n",
    "    'abstraction match': [level_1_concept_abstraction_match[concept] for concept in ordered_concepts],\n",
    "})\n",
    "alt.Chart(df, title='Abstraction Match per Superclass').mark_bar().encode(\n",
    "    x=alt.X('concept:N').sort('-y'),\n",
    "    y=alt.Y('abstraction match:Q')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08d75c3c-d8a2-4e80-9bfa-eff6419503f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-79d9c2061eeb46e697dd8c22654bfe77.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-79d9c2061eeb46e697dd8c22654bfe77.vega-embed details,\n",
       "  #altair-viz-79d9c2061eeb46e697dd8c22654bfe77.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-79d9c2061eeb46e697dd8c22654bfe77\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-79d9c2061eeb46e697dd8c22654bfe77\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-79d9c2061eeb46e697dd8c22654bfe77\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-cc869dc6bc7d8e074eb63a7a656c3241\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"high-level concept\", \"type\": \"nominal\"}, \"x\": {\"field\": \"concept\", \"sort\": \"-y\", \"type\": \"nominal\"}, \"y\": {\"field\": \"abstraction match\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Abstraction Match per Class\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-cc869dc6bc7d8e074eb63a7a656c3241\": [{\"concept\": \"oak_tree\", \"abstraction match\": 0.8613921403884888, \"high-level concept\": \"trees\"}, {\"concept\": \"boy\", \"abstraction match\": 0.7948678135871887, \"high-level concept\": \"people\"}, {\"concept\": \"maple_tree\", \"abstraction match\": 0.7491366863250732, \"high-level concept\": \"trees\"}, {\"concept\": \"girl\", \"abstraction match\": 0.724697470664978, \"high-level concept\": \"people\"}, {\"concept\": \"baby\", \"abstraction match\": 0.7070233225822449, \"high-level concept\": \"people\"}, {\"concept\": \"man\", \"abstraction match\": 0.6654984951019287, \"high-level concept\": \"people\"}, {\"concept\": \"poppy\", \"abstraction match\": 0.6249228119850159, \"high-level concept\": \"flowers\"}, {\"concept\": \"apple\", \"abstraction match\": 0.6244350671768188, \"high-level concept\": \"fruit_and_vegetables\"}, {\"concept\": \"pine_tree\", \"abstraction match\": 0.6087632179260254, \"high-level concept\": \"trees\"}, {\"concept\": \"woman\", \"abstraction match\": 0.5970258712768555, \"high-level concept\": \"people\"}, {\"concept\": \"sea\", \"abstraction match\": 0.5923061370849609, \"high-level concept\": \"large_natural_outdoor_scenes\"}, {\"concept\": \"rose\", \"abstraction match\": 0.5838879346847534, \"high-level concept\": \"flowers\"}, {\"concept\": \"willow_tree\", \"abstraction match\": 0.5801346302032471, \"high-level concept\": \"trees\"}, {\"concept\": \"bed\", \"abstraction match\": 0.5787810683250427, \"high-level concept\": \"household_furniture\"}, {\"concept\": \"orange\", \"abstraction match\": 0.5654146075248718, \"high-level concept\": \"fruit_and_vegetables\"}, {\"concept\": \"plain\", \"abstraction match\": 0.5498455166816711, \"high-level concept\": \"large_natural_outdoor_scenes\"}, {\"concept\": \"tulip\", \"abstraction match\": 0.5449640154838562, \"high-level concept\": \"flowers\"}, {\"concept\": \"cloud\", \"abstraction match\": 0.5227534770965576, \"high-level concept\": \"large_natural_outdoor_scenes\"}, {\"concept\": \"castle\", \"abstraction match\": 0.5167645215988159, \"high-level concept\": \"large_man-made_outdoor_things\"}, {\"concept\": \"palm_tree\", \"abstraction match\": 0.48913219571113586, \"high-level concept\": \"trees\"}, {\"concept\": \"pickup_truck\", \"abstraction match\": 0.4736098349094391, \"high-level concept\": \"vehicles_1\"}, {\"concept\": \"wardrobe\", \"abstraction match\": 0.4647940397262573, \"high-level concept\": \"household_furniture\"}, {\"concept\": \"hamster\", \"abstraction match\": 0.4635382890701294, \"high-level concept\": \"small_mammals\"}, {\"concept\": \"chair\", \"abstraction match\": 0.46235373616218567, \"high-level concept\": \"household_furniture\"}, {\"concept\": \"cockroach\", \"abstraction match\": 0.4490170180797577, \"high-level concept\": \"insects\"}, {\"concept\": \"plate\", \"abstraction match\": 0.4436414837837219, \"high-level concept\": \"food_containers\"}, {\"concept\": \"couch\", \"abstraction match\": 0.4385313391685486, \"high-level concept\": \"household_furniture\"}, {\"concept\": \"pear\", \"abstraction match\": 0.4383189082145691, \"high-level concept\": \"fruit_and_vegetables\"}, {\"concept\": \"bowl\", \"abstraction match\": 0.43130308389663696, \"high-level concept\": \"food_containers\"}, {\"concept\": \"whale\", \"abstraction match\": 0.4300280511379242, \"high-level concept\": \"aquatic_mammals\"}, {\"concept\": \"television\", \"abstraction match\": 0.42759597301483154, \"high-level concept\": \"household_electrical_devices\"}, {\"concept\": \"dolphin\", \"abstraction match\": 0.42522814869880676, \"high-level concept\": \"aquatic_mammals\"}, {\"concept\": \"road\", \"abstraction match\": 0.42473965883255005, \"high-level concept\": \"large_man-made_outdoor_things\"}, {\"concept\": \"sweet_pepper\", \"abstraction match\": 0.4236488938331604, \"high-level concept\": \"fruit_and_vegetables\"}, {\"concept\": \"tiger\", \"abstraction match\": 0.4218918979167938, \"high-level concept\": \"large_carnivores\"}, {\"concept\": \"mouse\", \"abstraction match\": 0.4210396707057953, \"high-level concept\": \"small_mammals\"}, {\"concept\": \"orchid\", \"abstraction match\": 0.41763684153556824, \"high-level concept\": \"flowers\"}, {\"concept\": \"can\", \"abstraction match\": 0.3938906192779541, \"high-level concept\": \"food_containers\"}, {\"concept\": \"lion\", \"abstraction match\": 0.3920961618423462, \"high-level concept\": \"large_carnivores\"}, {\"concept\": \"telephone\", \"abstraction match\": 0.39079388976097107, \"high-level concept\": \"household_electrical_devices\"}, {\"concept\": \"otter\", \"abstraction match\": 0.39055466651916504, \"high-level concept\": \"aquatic_mammals\"}, {\"concept\": \"ray\", \"abstraction match\": 0.38087376952171326, \"high-level concept\": \"fish\"}, {\"concept\": \"seal\", \"abstraction match\": 0.3803529143333435, \"high-level concept\": \"aquatic_mammals\"}, {\"concept\": \"beetle\", \"abstraction match\": 0.37780389189720154, \"high-level concept\": \"insects\"}, {\"concept\": \"sunflower\", \"abstraction match\": 0.3716505169868469, \"high-level concept\": \"flowers\"}, {\"concept\": \"camel\", \"abstraction match\": 0.37064921855926514, \"high-level concept\": \"large_omnivores_and_herbivores\"}, {\"concept\": \"trout\", \"abstraction match\": 0.3689180016517639, \"high-level concept\": \"fish\"}, {\"concept\": \"shark\", \"abstraction match\": 0.36744067072868347, \"high-level concept\": \"fish\"}, {\"concept\": \"crab\", \"abstraction match\": 0.36239033937454224, \"high-level concept\": \"non-insect_invertebrates\"}, {\"concept\": \"elephant\", \"abstraction match\": 0.36098265647888184, \"high-level concept\": \"large_omnivores_and_herbivores\"}, {\"concept\": \"cattle\", \"abstraction match\": 0.35978367924690247, \"high-level concept\": \"large_omnivores_and_herbivores\"}, {\"concept\": \"cup\", \"abstraction match\": 0.35059654712677, \"high-level concept\": \"food_containers\"}, {\"concept\": \"lizard\", \"abstraction match\": 0.34857431054115295, \"high-level concept\": \"reptiles\"}, {\"concept\": \"bus\", \"abstraction match\": 0.3436109125614166, \"high-level concept\": \"vehicles_1\"}, {\"concept\": \"house\", \"abstraction match\": 0.34260091185569763, \"high-level concept\": \"large_man-made_outdoor_things\"}, {\"concept\": \"flatfish\", \"abstraction match\": 0.3418499231338501, \"high-level concept\": \"fish\"}, {\"concept\": \"raccoon\", \"abstraction match\": 0.3367738425731659, \"high-level concept\": \"medium_mammals\"}, {\"concept\": \"squirrel\", \"abstraction match\": 0.3336784243583679, \"high-level concept\": \"small_mammals\"}, {\"concept\": \"rabbit\", \"abstraction match\": 0.33270710706710815, \"high-level concept\": \"small_mammals\"}, {\"concept\": \"shrew\", \"abstraction match\": 0.3316744565963745, \"high-level concept\": \"small_mammals\"}, {\"concept\": \"table\", \"abstraction match\": 0.3314119279384613, \"high-level concept\": \"household_furniture\"}, {\"concept\": \"wolf\", \"abstraction match\": 0.32633116841316223, \"high-level concept\": \"large_carnivores\"}, {\"concept\": \"beaver\", \"abstraction match\": 0.3185562193393707, \"high-level concept\": \"aquatic_mammals\"}, {\"concept\": \"possum\", \"abstraction match\": 0.3139510452747345, \"high-level concept\": \"medium_mammals\"}, {\"concept\": \"clock\", \"abstraction match\": 0.3125559985637665, \"high-level concept\": \"household_electrical_devices\"}, {\"concept\": \"porcupine\", \"abstraction match\": 0.30948305130004883, \"high-level concept\": \"medium_mammals\"}, {\"concept\": \"leopard\", \"abstraction match\": 0.3085879385471344, \"high-level concept\": \"large_carnivores\"}, {\"concept\": \"aquarium_fish\", \"abstraction match\": 0.3079243302345276, \"high-level concept\": \"fish\"}, {\"concept\": \"bee\", \"abstraction match\": 0.30688637495040894, \"high-level concept\": \"insects\"}, {\"concept\": \"crocodile\", \"abstraction match\": 0.30635401606559753, \"high-level concept\": \"reptiles\"}, {\"concept\": \"bridge\", \"abstraction match\": 0.3060298264026642, \"high-level concept\": \"large_man-made_outdoor_things\"}, {\"concept\": \"caterpillar\", \"abstraction match\": 0.3051755130290985, \"high-level concept\": \"insects\"}, {\"concept\": \"keyboard\", \"abstraction match\": 0.3024590313434601, \"high-level concept\": \"household_electrical_devices\"}, {\"concept\": \"bottle\", \"abstraction match\": 0.3023868203163147, \"high-level concept\": \"food_containers\"}, {\"concept\": \"spider\", \"abstraction match\": 0.3016860783100128, \"high-level concept\": \"non-insect_invertebrates\"}, {\"concept\": \"butterfly\", \"abstraction match\": 0.2912274897098541, \"high-level concept\": \"insects\"}, {\"concept\": \"tractor\", \"abstraction match\": 0.2862580418586731, \"high-level concept\": \"vehicles_2\"}, {\"concept\": \"bicycle\", \"abstraction match\": 0.2856769263744354, \"high-level concept\": \"vehicles_1\"}, {\"concept\": \"lawn_mower\", \"abstraction match\": 0.28537818789482117, \"high-level concept\": \"vehicles_2\"}, {\"concept\": \"mountain\", \"abstraction match\": 0.28382745385169983, \"high-level concept\": \"large_natural_outdoor_scenes\"}, {\"concept\": \"lobster\", \"abstraction match\": 0.27656033635139465, \"high-level concept\": \"non-insect_invertebrates\"}, {\"concept\": \"skyscraper\", \"abstraction match\": 0.2756025791168213, \"high-level concept\": \"large_man-made_outdoor_things\"}, {\"concept\": \"motorcycle\", \"abstraction match\": 0.27127084136009216, \"high-level concept\": \"vehicles_1\"}, {\"concept\": \"turtle\", \"abstraction match\": 0.2688720226287842, \"high-level concept\": \"reptiles\"}, {\"concept\": \"skunk\", \"abstraction match\": 0.26355648040771484, \"high-level concept\": \"medium_mammals\"}, {\"concept\": \"chimpanzee\", \"abstraction match\": 0.2629453241825104, \"high-level concept\": \"large_omnivores_and_herbivores\"}, {\"concept\": \"train\", \"abstraction match\": 0.26230984926223755, \"high-level concept\": \"vehicles_1\"}, {\"concept\": \"forest\", \"abstraction match\": 0.2594723701477051, \"high-level concept\": \"large_natural_outdoor_scenes\"}, {\"concept\": \"dinosaur\", \"abstraction match\": 0.25915318727493286, \"high-level concept\": \"reptiles\"}, {\"concept\": \"snake\", \"abstraction match\": 0.25675323605537415, \"high-level concept\": \"reptiles\"}, {\"concept\": \"snail\", \"abstraction match\": 0.254373162984848, \"high-level concept\": \"non-insect_invertebrates\"}, {\"concept\": \"tank\", \"abstraction match\": 0.25291067361831665, \"high-level concept\": \"vehicles_2\"}, {\"concept\": \"kangaroo\", \"abstraction match\": 0.2507270574569702, \"high-level concept\": \"large_omnivores_and_herbivores\"}, {\"concept\": \"bear\", \"abstraction match\": 0.245938241481781, \"high-level concept\": \"large_carnivores\"}, {\"concept\": \"lamp\", \"abstraction match\": 0.24140484631061554, \"high-level concept\": \"household_electrical_devices\"}, {\"concept\": \"worm\", \"abstraction match\": 0.21890413761138916, \"high-level concept\": \"non-insect_invertebrates\"}, {\"concept\": \"fox\", \"abstraction match\": 0.21641680598258972, \"high-level concept\": \"medium_mammals\"}, {\"concept\": \"mushroom\", \"abstraction match\": 0.1794133335351944, \"high-level concept\": \"fruit_and_vegetables\"}, {\"concept\": \"streetcar\", \"abstraction match\": 0.17197461426258087, \"high-level concept\": \"vehicles_2\"}, {\"concept\": \"rocket\", \"abstraction match\": 0.17174531519412994, \"high-level concept\": \"vehicles_2\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute level-1 abstraction match aggregated per instance label\n",
    "instance_per_class = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in instance_per_class:\n",
    "        instance_per_class[label] = set([])\n",
    "    instance_per_class[label].add(i)\n",
    "    \n",
    "class_abstraction_match = {}\n",
    "for concept, instances in tqdm(instance_per_class.items()):\n",
    "    instance_fitted_abstractions = [fitted_abstraction for i, fitted_abstraction in enumerate(fitted_abstractions) if i in instances]\n",
    "    match = metrics.abstraction_match(instance_fitted_abstractions, 1)\n",
    "    class_abstraction_match[concept] = match\n",
    "    \n",
    "ordered_concepts = sorted(class_abstraction_match.keys(), key=lambda c: class_abstraction_match[c], reverse=True)\n",
    "df = pd.DataFrame.from_dict({\n",
    "    'concept': [cifar_metadata.CLASS_LABELS[concept] for concept in ordered_concepts],\n",
    "    'abstraction match': [class_abstraction_match[concept] for concept in ordered_concepts],\n",
    "    'high-level concept': [cifar_metadata.SUPERCLASS_LABELS[cifar_metadata.CLASS_TO_SUPERCLASS[concept]] for concept in ordered_concepts],\n",
    "})\n",
    "alt.Chart(df, title='Abstraction Match per Class').mark_bar().encode(\n",
    "    x=alt.X('concept:N').sort('-y'),\n",
    "    y=alt.Y('abstraction match:Q'),\n",
    "    color=alt.Color('high-level concept:N')\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8cfd6-dfd7-43e0-8f71-d792859d6dbd",
   "metadata": {},
   "source": [
    "### Query for model behavior types\n",
    "We can use abstraction alignment to query for common pattens in model behavior. We define a query over the fitted abstractions and return all the instances that match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e40c3529-edac-401c-9b3a-e16adb91573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(indicies, num_examples):\n",
    "    if len(indicies) > 0:\n",
    "        example_inds = np.random.choice(indicies, num_examples)\n",
    "        plot_images(example_inds)\n",
    "        plt.show()\n",
    "        print(cifar.show(trees[example_inds[0]]))\n",
    "\n",
    "def plot_images(indicies):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=len(indicies))\n",
    "    if type(ax) != list:\n",
    "        ax = [ax]\n",
    "    for i, index in enumerate(indicies):\n",
    "        ax[i].imshow(cifar_util.unnorm_cifar_image(test_dataset[index][0].permute(1, 2, 0)))\n",
    "        ax[i].axis('off')\n",
    "    return fig\n",
    "\n",
    "def get_nodes_at_level(abstraction_graph, level, non_zero=True):\n",
    "    nodes = abstraction_graph.filter_nodes(lambda x: abstraction_graph.depth(x) == level)\n",
    "    if non_zero:\n",
    "        nodes = [node for node in nodes if node.data is not None and node.data >= 0.01]\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "60c5cc4b-7910-4d2a-b3dd-03b0ce395213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:15<00:00, 638.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2976 images where the model is fully confident in one output.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root (1.00)\n",
      "├── large_natural_outdoor_scenes (1.00)\n",
      "│   ├── cloud (1.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fully confident in an output concept\n",
    "fully_confident = []\n",
    "for i, fitted_abstraction in enumerate(tqdm(fitted_abstractions)):\n",
    "    non_zero_leaf_nodes = get_nodes_at_level(fitted_abstraction, 2, True)\n",
    "    if len(non_zero_leaf_nodes) == 1:\n",
    "        fully_confident.append(i)\n",
    "print(f'{len(fully_confident)} images where the model is fully confident in one output concept.')\n",
    "show_examples(fully_confident, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "078b14ef-a4cd-4f3e-8c7c-bd32b984a4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 381.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 images where the model is split between two branches through two superclass.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root (1.00)\n",
      "├── vehicles_1 (0.56)\n",
      "│   └── train (0.56)\n",
      "└── vehicles_2 (0.44)\n",
      "    ├── streetcar (0.44)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confidence split between two independent branches\n",
    "two_branches = []\n",
    "for i, fitted_abstraction in enumerate(tqdm(fitted_abstractions)):\n",
    "    non_zero_level_1_nodes = get_nodes_at_level(fitted_abstraction, 1, True)\n",
    "    non_zero_leaf_nodes = get_nodes_at_level(fitted_abstraction, 2, True)\n",
    "    if len(non_zero_leaf_nodes) != 2 or len(non_zero_level_1_nodes) != 2:\n",
    "        continue\n",
    "    if 0.4 <= np.max([node.data for node in non_zero_leaf_nodes]) <= 0.6 and 0.4 <= np.max([node.data for node in non_zero_level_1_nodes]) <= 0.6:\n",
    "        two_branches.append(i)\n",
    "\n",
    "print(f'{len(two_branches)} images where the model is split between two branches through two superclass.')\n",
    "show_examples(two_branches, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87cdc1-0abf-4894-b993-50af55b59aeb",
   "metadata": {},
   "source": [
    "### Concept Co-Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "69aee765-c56e-48d7-b5ec-1e60c6db4f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:17<00:00, 38.90it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs_per_instance = []\n",
    "for fitted_abstraction in fitted_abstractions:\n",
    "    output = {node.identifier: node.data for node in fitted_abstraction.all_nodes()}\n",
    "    outputs_per_instance.append(output)\n",
    "joint_entropy = metrics.joint_entropy(outputs_per_instance, 0.0001)\n",
    "max_entropy = stats.entropy([0.5,0.5])*len(fitted_abstractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f47fea93-3ae0-43f6-990d-a67125b83874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHEST OVERALL CONFUSION:\n",
      "household_electrical_devices,lamp --- 20.18%\n",
      "non-insect_invertebrates,reptiles --- 20.03%\n",
      "medium_mammals,small_mammals --- 19.84%\n",
      "bear,large_carnivores --- 19.20%\n",
      "large_carnivores,medium_mammals --- 18.96%\n"
     ]
    }
   ],
   "source": [
    "# Highest overall confusion\n",
    "joint_entropy_non_root = {k:v for k, v in joint_entropy.items() if 'root' not in k}\n",
    "sorted_pairs = [k for k, v in sorted(joint_entropy.items(), key=lambda item: item[1], reverse=True)]\n",
    "print('HIGHEST OVERALL CONFUSION:')\n",
    "for i in range(5):\n",
    "    print(f'{sorted_pairs[i]} --- {joint_entropy[sorted_pairs[i]]/max_entropy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d8277e6e-98a2-4f0c-9075-e3757a2c29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHEST SUPERCLASS CONFUSION:\n",
      "non-insect_invertebrates,reptiles --- 20.03%\n",
      "medium_mammals,small_mammals --- 19.84%\n",
      "large_carnivores,medium_mammals --- 18.96%\n",
      "large_carnivores,large_omnivores_and_herbivores --- 18.92%\n",
      "insects,non-insect_invertebrates --- 18.71%\n"
     ]
    }
   ],
   "source": [
    "# Confusion between superclass nodes\n",
    "superclass_pairs = [pair for pair in sorted_pairs if pair.split(',')[0] in cifar_metadata.SUPERCLASS_LABELS and pair.split(',')[1] in cifar_metadata.SUPERCLASS_LABELS]\n",
    "print('HIGHEST SUPERCLASS CONFUSION:')\n",
    "for i in range(5):\n",
    "    print(f'{superclass_pairs[i]} --- {joint_entropy[superclass_pairs[i]]/max_entropy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31006a3d-d4ec-4cf6-95b8-551ddcada600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
